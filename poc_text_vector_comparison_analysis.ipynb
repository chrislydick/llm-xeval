{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_APIKEY'))\n",
    "\n",
    "# Load a pre-trained text embedding model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# List of Models to compare\n",
    "models =    { \n",
    "                \"gpt-3.5-turbo\", \n",
    "                \"gpt-4\", \n",
    "                \"gpt-4o\" \n",
    "            }\n",
    "\n",
    "# Define the prompts to compare\n",
    "prompts =   {\n",
    "                \"Explain who are the best cloud infrastructure providers and what they offer as differentiating features.\", \n",
    "                \"Is Azure better than AWS? If so, Why?\", \n",
    "                \"Is GCP better than Azure? If so, Why?\",\n",
    "            }\n",
    "\n",
    "\n",
    "model_prompt_key = [f\"'{model}': '{prompt}'\" for model in models for prompt in prompts]\n",
    "\n",
    "def get_response(prompt, model=\"gpt-4o\"):\n",
    "    response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_text_vector(text):\n",
    "    inputs = tokenizer([text], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return torch.mean(outputs.last_hidden_state, dim=1).detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all responses for the models and prompts\n",
    "responses = [get_response(prompt, model) for model in models for prompt in prompts]\n",
    "\n",
    "# Generate the vectors for all responses  \n",
    "vectors = [get_text_vector(response) for response in responses]\n",
    "vector_array = np.vstack(vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean and standard deviation\n",
    "median_vector = np.median(vector_array, axis=0)\n",
    "mean_vector = np.mean(vector_array, axis=0)\n",
    "std_deviation = np.std(vector_array, axis=0)\n",
    "\n",
    "# Calculated euclidean distances between vectors\n",
    "distances = cdist(vector_array, vector_array, metric='euclidean')\n",
    "\n",
    "# Use z-scores to identify outliers\n",
    "mean_distance = np.mean(distances)\n",
    "std_distance = np.std(distances)\n",
    "z_scores = zscore(distances, axis=None)\n",
    "\n",
    "\n",
    "# Zscores using 2.5 standard deviations as threshold, ~98.8% [0.62%, 99.38%] of the data should be within this range\n",
    "outlier_indices = np.where((z_scores > 2.5) | (z_scores < -2.5))\n",
    "outlier_vector = set(outlier_indices[0])\n",
    "\n",
    "average_distances = np.mean(distances, axis=1)\n",
    "\n",
    "most_outlying_index = np.argmax(average_distances)\n",
    "ranking_indices = np.argsort(average_distances)[::-1]  # Sort in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'gpt-4': 'Is Azure better than AWS? If so, Why?'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'gpt-4': 'Is Azure better than AWS? If so, Why?'</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'gpt-4': 'Is GCP better than Azure? If so, Why?'</th>\n",
       "      <td>1.926646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'gpt-4': 'Explain who are the best cloud infrastructure providers and what they offer as differentiating features.'</th>\n",
       "      <td>2.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'gpt-4o': 'Is Azure better than AWS? If so, Why?'</th>\n",
       "      <td>3.059673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    'gpt-4': 'Is Azure better than AWS? If so, Why?'\n",
       "'gpt-4': 'Is Azure better than AWS? If so, Why?'                                            0.000000\n",
       "'gpt-4': 'Is GCP better than Azure? If so, Why?'                                            1.926646\n",
       "'gpt-4': 'Explain who are the best cloud infras...                                          2.439336\n",
       "'gpt-4o': 'Is Azure better than AWS? If so, Why?'                                           3.059673"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results\n",
    "#print(\"Responses:\", pd.DataFrame(responses))\n",
    "#print(\"Median Vector:\", median_vector)\n",
    "#print(\"Standard Deviation:\", std_deviation)\n",
    "print(\"Example Comparison:\")\n",
    "pd.DataFrame(distances, columns=model_prompt_key, index=model_prompt_key).head(1).transpose().head(4)\n",
    "#print(\"Outlier Indices:\", outlier_indices)\n",
    "#print(\"Outlier Vector:\", outlier_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 5:  Avg Distance: 3.30 \t'gpt-4o': 'Explain who are the best cloud infrastructure providers and what they offer as differentiating features.'\n",
      "Vector 6:  Avg Distance: 2.69 \t'gpt-3.5-turbo': 'Is Azure better than AWS? If so, Why?'\n",
      "Vector 2:  Avg Distance: 2.54 \t'gpt-4': 'Explain who are the best cloud infrastructure providers and what they offer as differentiating features.'\n",
      "Vector 4:  Avg Distance: 2.49 \t'gpt-4o': 'Is GCP better than Azure? If so, Why?'\n",
      "Vector 1:  Avg Distance: 2.48 \t'gpt-4': 'Is GCP better than Azure? If so, Why?'\n",
      "Vector 3:  Avg Distance: 2.45 \t'gpt-4o': 'Is Azure better than AWS? If so, Why?'\n",
      "Vector 0:  Avg Distance: 2.37 \t'gpt-4': 'Is Azure better than AWS? If so, Why?'\n",
      "Vector 8:  Avg Distance: 2.37 \t'gpt-3.5-turbo': 'Explain who are the best cloud infrastructure providers and what they offer as differentiating features.'\n",
      "Vector 7:  Avg Distance: 2.36 \t'gpt-3.5-turbo': 'Is GCP better than Azure? If so, Why?'\n"
     ]
    }
   ],
   "source": [
    "for index in ranking_indices:\n",
    "    print(f\"Vector {index}:  Avg Distance: {average_distances[index]:2.2f} \\t{model_prompt_key[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
